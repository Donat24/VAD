{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Program Files\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Program Files\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from IPython.display import clear_output, display\n",
    "import json\n",
    "import librosa\n",
    "import librosa.display as dsp\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "#Eigene Sachen\n",
    "from data.data import *\n",
    "from util.util import *\n",
    "from util.datasets import *\n",
    "from util.audio_processing import *\n",
    "import util.plot as plot\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to C:\\Users\\Jonas/.cache\\torch\\hub\\master.zip\n",
      "C:\\Users\\Jonas\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501: UserWarning: operator () profile_node %669 : int[] = prim::profile_ivalue(%667)\n",
      " does not have profile information (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\third_party\\nvfuser\\csrc\\graph_fuser.cpp:108.)\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m#Iterriert über Sample\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     10\u001b[0m         \n\u001b[0;32m     11\u001b[0m         \u001b[39m#Iterriert Sample\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m         \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(models\u001b[39m.\u001b[39msilerio\u001b[39m.\u001b[39mDATASET):\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m                 \u001b[39m#Prediction\u001b[39;00m\n\u001b[0;32m     15\u001b[0m                 pred \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39msilerio\u001b[39m.\u001b[39mpredict(x)\n\u001b[0;32m     17\u001b[0m                 \u001b[39m#Kürzt auf Ende\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\Documents\\Masterarbeit\\GIT\\VAD\\Scripte\\util\\datasets.py:193\u001b[0m, in \u001b[0;36mChunkedDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m    191\u001b[0m     \n\u001b[0;32m    192\u001b[0m     \u001b[39m#Lädt x, y für \u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n\u001b[0;32m    195\u001b[0m     \u001b[39m#Füllt Sample Länge auf\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_x_to_sample_length \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_y_to_sample_length:\n\u001b[0;32m    197\u001b[0m         \n\u001b[0;32m    198\u001b[0m         \u001b[39m#Errechnet\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\Documents\\Masterarbeit\\GIT\\VAD\\Scripte\\util\\datasets.py:148\u001b[0m, in \u001b[0;36mSpeakDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m    146\u001b[0m     \n\u001b[0;32m    147\u001b[0m     \u001b[39m#Lädt x\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     x, sr, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n\u001b[0;32m    150\u001b[0m     \u001b[39m#Erzeugt y\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_y(x,sr,info)\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\Documents\\Masterarbeit\\GIT\\VAD\\Scripte\\util\\datasets.py:47\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     44\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39miloc[n]\n\u001b[0;32m     46\u001b[0m \u001b[39m#lädt Datei\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m waveform, sample_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__getfile__(row\u001b[39m.\u001b[39;49mfilename), sr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_samplerate, mono\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfloat64\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     49\u001b[0m \u001b[39m#Tensor\u001b[39;00m\n\u001b[0;32m     50\u001b[0m waveform \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(waveform)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\core\\audio.py:193\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    190\u001b[0m     y \u001b[39m=\u001b[39m to_mono(y)\n\u001b[0;32m    192\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     y \u001b[39m=\u001b[39m resample(y, orig_sr\u001b[39m=\u001b[39;49msr_native, target_sr\u001b[39m=\u001b[39;49msr, res_type\u001b[39m=\u001b[39;49mres_type)\n\u001b[0;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     sr \u001b[39m=\u001b[39m sr_native\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\core\\audio.py:634\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample a time series from orig_sr to target_sr\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[39mBy default, this uses a high-quality method (`soxr_hq`) for band-limited sinc\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39m((117601,), (42668,))\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39m# First, validate the audio buffer\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m util\u001b[39m.\u001b[39;49mvalid_audio(y, mono\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m orig_sr \u001b[39m==\u001b[39m target_sr:\n\u001b[0;32m    637\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\util\\utils.py:315\u001b[0m, in \u001b[0;36mvalid_audio\u001b[1;34m(y, mono)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mif\u001b[39;00m mono \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    311\u001b[0m     \u001b[39mraise\u001b[39;00m ParameterError(\n\u001b[0;32m    312\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid shape for monophonic audio: ndim=\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mndim\u001b[39m:\u001b[39;00m\u001b[39md\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, shape=\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m     )\n\u001b[1;32m--> 315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39;49misfinite(y)\u001b[39m.\u001b[39mall():\n\u001b[0;32m    316\u001b[0m     \u001b[39mraise\u001b[39;00m ParameterError(\u001b[39m\"\u001b[39m\u001b[39mAudio buffer is not finite everywhere\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "accuracy = torchmetrics.classification.BinaryAccuracy()\n",
    "\n",
    "#Ergebnis\n",
    "pred_total = []\n",
    "y_total    = []\n",
    "\n",
    "#Iterriert über Sample\n",
    "with torch.no_grad():\n",
    "        \n",
    "        #Iterriert Sample\n",
    "        for x, y in iter(models.silerio.DATASET):\n",
    "\n",
    "                #Prediction\n",
    "                pred = models.silerio.predict(x)\n",
    "                \n",
    "                #Kürzt auf Ende\n",
    "                pred = pred[ : y.size(0) ]\n",
    "                \n",
    "                #Fügt Total an\n",
    "                pred_total.append(pred)\n",
    "                y_total.append(y)\n",
    "\n",
    "#Tensor\n",
    "y_total    = torch.hstack(y_total)\n",
    "pred_total = torch.hstack(pred_total)\n",
    "\n",
    "#Print für Accuracy\n",
    "print(\"Accuracy auf Batch:\", accuracy(pred_total, y_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
